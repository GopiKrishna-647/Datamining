{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff2489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext,SparkConf\n",
    "from random import randint\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "import itertools\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba471413",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "input_file_path = sys.argv[1]\n",
    "output_file_path = sys.argv[2]\n",
    "'''\n",
    "input_file_path = \"/Users/gopi/Desktop/Assignment3/yelp_train.csv\"\n",
    "output_file_path = \"/Users/gopi/Desktop/Assignment3/output_1.csv\"\n",
    "#SparkContext.setSystemProperty('spark.executor.memory', '2g')\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"assign-3-task-1\").set(\"spark.executor.memory\", \"4g\").set(\"spark.driver.memory\", \"4g\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afa595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#a = random.sample(range(1, sys.maxsize - 1), num_hash_functions)\n",
    "#b = random.sample(range(1, sys.maxsize - 1), num_hash_functions)\n",
    "num_hash_functions = 30\n",
    "a = [randint(1, 10001) for i in range(num_hash_functions)]\n",
    "b = [randint(1, 10001) for i in range(num_hash_functions)]\n",
    "\n",
    "def min_hashing(users_index, m):\n",
    "    result = []\n",
    "    for i in range(num_hash_functions):\n",
    "        min_value = math.inf\n",
    "        count = 0\n",
    "        l = []\n",
    "        for user_index in users_index:\n",
    "            hash_value = ((a[i] * user_index + b[i]) % 99991) % m\n",
    "            #if(hash_value == 0):\n",
    "             #   print(\"a is: \", a[i], \" b is : \", b[i], \" user_index is :\", user_index)\n",
    "            if(count == 0):\n",
    "                l.append(hash_value)\n",
    "            if hash_value < min_value: min_value = hash_value\n",
    "        #if count == 0: print(l)\n",
    "        result.append(min_value)\n",
    "    return result\n",
    "\n",
    "def split_into_bands(hash_indices, bands):\n",
    "    result = []\n",
    "    size = int(len(hash_indices)/bands)\n",
    "    for i in range(0,len(hash_indices), size):\n",
    "        band = hash_indices[i : i+size]\n",
    "        result.append((i,hash(tuple(band))))\n",
    "    return tuple(result)\n",
    "\n",
    "def verify_actual_similarity(candidate_pairs, business_user_map):\n",
    "    result = []\n",
    "    visited = set()\n",
    "    for sorted_pair in candidate_pairs:\n",
    "        #sorted_pair = tuple(sorted(pair))\n",
    "        if sorted_pair not in visited:\n",
    "            visited.add(sorted_pair)\n",
    "            set1 = business_user_map[sorted_pair[0]]\n",
    "            set2 = business_user_map[sorted_pair[1]]\n",
    "            numerator = set1.intersection(set2)\n",
    "            denominator = set1.union(set2)\n",
    "            sim = len(numerator)/len(denominator)\n",
    "            if(sim >= 0.5):\n",
    "                result.append(sorted_pair)\n",
    "    print(len(result))\n",
    "    print(result[:5])\n",
    "    return result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e6cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "initial_rdd = sc.textFile(input_file_path)\n",
    "first = initial_rdd.first()\n",
    "initial_rdd = initial_rdd.filter(lambda line : line != first).map(lambda line : line.split(\",\")).map(lambda line: (line[0], line[1]))\n",
    "\n",
    "user_index_rdd = initial_rdd.map(lambda x : x[0]).distinct().sortBy(lambda x: x).zipWithIndex().map(lambda x : (x[0],x[1]))\n",
    "user_index_map = user_index_rdd.collectAsMap()\n",
    "user_count = len(user_index_map)\n",
    "print(user_index_rdd.take(5))\n",
    "business_index_rdd = initial_rdd.map(lambda x : x[1]).distinct().sortBy(lambda x: x).zipWithIndex().map(lambda x : (x[0],x[1]))\n",
    "business_index_map = business_index_rdd.collectAsMap()\n",
    "print(business_index_rdd.take(5))\n",
    "\n",
    "num_users = user_index_rdd.count()\n",
    "#user_hash_index_rdd = user_index_rdd.map(lambda x : (x[1], get_hashed_index(x[1], num_users)))\n",
    "\n",
    "business_user_rdd = initial_rdd.map(lambda x : (business_index_map[x[1]], user_index_map[x[0]])).groupByKey().mapValues(set)\n",
    "business_user_map = business_user_rdd.collectAsMap()\n",
    "#print(business_user_rdd.take(5))\n",
    "signature_matrix_rdd = business_user_rdd.mapValues(lambda x : min_hashing(x, user_count))\n",
    "#signature_matrix_rdd.saveAsTextFile(\"/Users/gopi/Desktop/Assignment3/temp_1.csv\")\n",
    "print(signature_matrix_rdd.count())\n",
    "bands_rdd = signature_matrix_rdd.mapValues(lambda x : split_into_bands(x,num_hash_functions)).flatMap(lambda x : [(band_item, x[0]) for band_item in x[1]]).groupByKey().mapValues(set)\n",
    "#print(bands_rdd.take(5))\n",
    "candidate_items = bands_rdd.filter(lambda x : len(x[1]) > 1).map(lambda x : x[1]).flatMap(lambda x : [y for y in itertools.combinations(x,2)]).distinct().collect()\n",
    "#candidate_items = set(candidate_items)\n",
    "print(\"Length before verifying is : \", len(candidate_items))\n",
    "#print(candidate_items[:5])\n",
    "start_verify = time.time()\n",
    "a = verify_actual_similarity(candidate_items, business_user_map)\n",
    "print(len(a))\n",
    "end = time.time()\n",
    "\n",
    "print(\"time taken to verify is : \", (end - start_verify))\n",
    "print(\"Total time is :\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec76604",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (213, 42)\n",
    "b = 1\n",
    "a = a + (b,)\n",
    "print(a)\n",
    "c = tuple()\n",
    "c = c+a\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d7852f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
