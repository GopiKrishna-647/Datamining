{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "915e682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from pyspark import SparkContext\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc7274d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "filter_threshold = int(sys.argv[1])\n",
    "threshold = sys.argv[2]\n",
    "input_file_path = sys.argv[3]\n",
    "output_file_path = sys.argv[4]\n",
    "'''\n",
    "filter_threshold = 20\n",
    "threshold = 50\n",
    "input_file_path = \"/Users/gopi/Desktop/Assignment2/input2.csv\"\n",
    "output_file_path = \"/Users/gopi/Desktop/Assignment2/output2.csv\"\n",
    "sc = SparkContext.getOrCreate()\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86d6ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori(partition, total_length):\n",
    "    baskets = list(partition)\n",
    "    #print(baskets)\n",
    "    unique_items = set()\n",
    "    for basket in baskets:\n",
    "        for item in basket:\n",
    "            unique_items.add(item)\n",
    "    single_item_sets = list(unique_items)#list(set(i for sub in baskets for i in sub))\n",
    "    scaled_threshold = (len(baskets) / total_length) * threshold\n",
    "    #scaled_threshold = int(threshold / num_partitions)\n",
    "    #print(scaled_threshold)\n",
    "    candidates = list(combinations(single_item_sets,1))\n",
    "    support = get_support_candidates(candidates, baskets)\n",
    "    pruned_candidates = prune_candidates(support, scaled_threshold)\n",
    "    #print(pruned_candidates)\n",
    "    \n",
    "    result_set = []\n",
    "    result_set.append(pruned_candidates)\n",
    "    count = 2\n",
    "    while(len(pruned_candidates) > 0) :\n",
    "        time1 = time.time()\n",
    "        item_sets = combinations(pruned_candidates, 2)\n",
    "        item_sets = reformat_item_sets(item_sets, count)\n",
    "        #print(item_sets)\n",
    "        support = get_support_candidates(item_sets, baskets)\n",
    "        pruned_candidates = prune_candidates(support, scaled_threshold)\n",
    "        if len(pruned_candidates) > 0:\n",
    "            result_set.append(pruned_candidates)\n",
    "        print(\"time for 1 iteration is:\" , (time.time() - time1))\n",
    "        count+=1\n",
    "    #print(result_set)\n",
    "    return result_set   \n",
    "    \n",
    "def reformat_item_sets(item_sets, size):\n",
    "    result_dict = {}\n",
    "    for item in item_sets:\n",
    "        new_tuple = tuple(set(item[0]).union(set(item[1])))\n",
    "        if(size == len(new_tuple)):\n",
    "            new_tuple = tuple(sorted(new_tuple))\n",
    "            if new_tuple not in result_dict:\n",
    "                result_dict[new_tuple] = None\n",
    "    return list(result_dict.keys())\n",
    "\n",
    "def get_single_item_sets(baskets) :\n",
    "    result = set()\n",
    "    for basket in baskets:\n",
    "        for item in basket:\n",
    "            result.add(item)\n",
    "    return result\n",
    "\n",
    "def get_support_candidates(candidates, baskets) :\n",
    "    support = {}\n",
    "    for candidate in candidates:\n",
    "        candidate_set = set(candidate)\n",
    "        #print(candidate_set)\n",
    "        for basket in baskets:\n",
    "            if candidate_set.issubset(set(basket)):\n",
    "                support[candidate] = support[candidate] + 1 if candidate in support else 1\n",
    "    #print(support)\n",
    "    return support\n",
    "\n",
    "def prune_candidates(items, support):\n",
    "    filtered_keys = list(dict(filter(lambda item : item[1] >= support, items.items())).keys())\n",
    "    filtered_keys = sorted(filtered_keys)\n",
    "    return filtered_keys\n",
    "\n",
    "def son(partition, candidates):\n",
    "    result = {}\n",
    "    baskets = list(partition)\n",
    "    result = get_support_candidates(candidates, baskets)\n",
    "    return list(result.items())\n",
    "\n",
    "def write_data_to_file(file_path, file_mode, item_sets, data_type):\n",
    "    file=open(file_path,file_mode);\n",
    "    file.write(data_type);\n",
    "    file.write(\"\\n\")\n",
    "    \n",
    "    result = defaultdict(lambda : [])\n",
    "    \n",
    "    for item in item_sets:\n",
    "        length = len(item)\n",
    "        if(length == 1):\n",
    "            result[length].append(\"(\" + item[0] + \")\")\n",
    "        else:\n",
    "            result[length].append(str(item))\n",
    "    keys = sorted(list(result.keys()))\n",
    "    \n",
    "    for key in keys:\n",
    "        string = \",\".join(sorted(result[key]))\n",
    "        file.write(str(string))\n",
    "        file.write(\"\\n\\n\")\n",
    "    \n",
    "    file.close()\n",
    "    \n",
    "def custom_hash(x) :\n",
    "    return hash(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da557dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for pre_processing is :  1.7194669246673584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "/opt/homebrew/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "time for 1 iteration is: 140.58526992797852                         (0 + 5) / 5]\n",
      "time for 1 iteration is: 0.056791067123413086\n",
      "time for 1 iteration is: 0.004128217697143555\n",
      "time for 1 iteration is: 2.1457672119140625e-06\n",
      "/opt/homebrew/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "time for 1 iteration is: 141.78237390518188                         (1 + 4) / 5]\n",
      "time for 1 iteration is: 0.03862118721008301\n",
      "time for 1 iteration is: 0.003522157669067383\n",
      "time for 1 iteration is: 145.9035358428955                          (2 + 3) / 5]\n",
      "time for 1 iteration is: 0.07236599922180176\n",
      "time for 1 iteration is: 0.017204999923706055\n",
      "time for 1 iteration is: 0.006567239761352539\n",
      "time for 1 iteration is: 0.004725933074951172\n",
      "time for 1 iteration is: 154.103924036026===>                       (3 + 2) / 5]\n",
      "time for 1 iteration is: 0.06432676315307617\n",
      "time for 1 iteration is: 0.008909940719604492\n",
      "time for 1 iteration is: 0.0007832050323486328\n",
      "time for 1 iteration is: 1.9073486328125e-06\n",
      "/opt/homebrew/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "time for 1 iteration is: 154.89326095581055=============>           (4 + 1) / 5]\n",
      "time for 1 iteration is: 0.034636735916137695\n",
      "time for 1 iteration is: 0.007216930389404297\n",
      "time for 1 iteration is: 0.0008037090301513672\n",
      "/opt/homebrew/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'4710015103479', '4710105045450', '4710160013067', '4712814168888', '4710632001622', '4710094020568', '4710199010174', '4710943101059', '4710160013074', '4710008242154', '4710883000061', '4710363522007', '4710731041802', '4710105045320', '4710085120093', '4711186319911', '4710321871055', '4713428000151', '4712277820637', '4710036006223', '4710386123229', '4710043105124', '4710883000092'}, {'16379130125', '4711080010112', '8851991511127', '4716426880411', '4710126194298', '4711109808058', '4717265991788', '4715874000235', '4710583350718', '4711713390031', '4715398208339', '4902738431155', '4712815116192', '4710094021572', '4712820617769', '20149772', '4710144101452', '4710017089085', '4713089003003', '4903301563495', '4710154012144', '4710543214012', '4715398106864', '4712815116185', '4710035310055', '4719860715110'}, {'2250271000218', '4711080010112', '4710105010175', '4710543111014', '4710030343508', '4719090105002', '4710861700020', '4710105015125', '4710088436344', '4710088410382', '4710015103370', '4711524001041', '4710088410290', '4710085171491', '4710175567111', '4714617946069', '4712789000138', '4710572001249', '8801062145492', '4710095937001', '4714981010038', '4710323168108', '4710777112269', '4710579101010', '4710265849066', '4710421090011', '20535407', '4710172030069', '4710626844013', '4710504000128', '4710088410610', '4710088410139', '4711447000688', '4711437000025', '4710572001225', '4716782102011', '4710167221014', '4710543214012', '4711437000018', '4710626111610', '4710088431295', '4710088410207', '4715398106864', '4711634002570', '4710109770396', '4710167111018', '4710515535107', '4710088432292'}, {'4710543511036', '4710290003082', '4710015104001', '8934614019061', '4710054503216', '4710176011040', '4711269679000', '4712246663166', '4710015103066', '76150215281', '4710063422355', '4710085120628', '4710011411479', '20412074', '4710290006014', '4710097110730', '4710085120093', '4710085172696', '4710085172702', '76150430530', '4710362020108', '4891996000220', '4710543511029', '4710047505081'}, {'4710572001256', '4710570000527', '4710035311106', '4710105051567', '4710105045221', '4710095987402', '4711258004110', '4710088443328', '4710857000066', '4710857000042', '4710011412148', '4710011409025', '4710088620156', '4714981010038', '4710857000059', '4710583110015', '4710857472689', '4712789000114', '4903316464015', '4710191030002', '4710022237501', '4710321790509', '4710022275503', '4710943101318', '4714562840054'}]\n",
      "time taken for candidate items is : 164.87962818145752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 169.81505298614502\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "'''\n",
    "initial_rdd = sc.textFile(input_file_path)\n",
    "first = initial_rdd.first()\n",
    "intermediate_data = initial_rdd.filter(lambda x : x != first).map(lambda line: line.split(\",\")).map(lambda x : [x[0].replace('\\\"', ''), x[1].replace('\\\"', '').lstrip('0'), x[5].replace('\\\"', '').lstrip('0')]).map(lambda x : [x[0] + \"-\" + x[1],  x[2]]).collect()\n",
    "'''\n",
    "\n",
    "intermediate_data = []\n",
    "with open(input_file_path,'r') as input_file:\n",
    "    reader = csv.reader(input_file)\n",
    "    headers = next(reader)\n",
    "    for row in reader:\n",
    "        date = row[0].replace('\\\"', '')\n",
    "        customer_id = row[1].replace('\\\"', '').lstrip('0')\n",
    "        product_id = row[5].replace('\\\"', '').lstrip('0')\n",
    "        intermediate_data.append([date + \"-\" + customer_id, product_id])\n",
    "\n",
    "header = ['DATE-CUSTOMER_ID','PRODUCT_ID']\n",
    "\n",
    "with open(\"customer_product_csv.csv\", 'w', newline = '') as file:\n",
    "    write = csv.writer(file)\n",
    "    write.writerow(header)\n",
    "    write.writerows(intermediate_data)\n",
    "    file.close()\n",
    "    \n",
    "print(\"time taken for pre_processing is : \", (time.time() - start_time))\n",
    "\n",
    "rdd = sc.textFile('customer_product.csv')\n",
    "first = rdd.first()\n",
    "rdd = rdd.filter(lambda x : x != first).map(lambda row : row.split(\",\")).map(lambda row : (row[0], row[1])).groupByKey().mapValues(set).filter(lambda row : len(row[1]) > filter_threshold).map(lambda row : (row[0], row[1]))\n",
    "num_partitions = rdd.getNumPartitions()\n",
    "total_length = rdd.count()\n",
    "if num_partitions < int(total_length / 1000):\n",
    "    rdd = rdd.partitionBy(int(total_length / 1000))\n",
    "rdd = rdd.map(lambda x : x[1]).cache()\n",
    "time1 = time.time()\n",
    "num_partitions = rdd.getNumPartitions()\n",
    "print(total_length)\n",
    "candidate_items = rdd.mapPartitions(lambda partition : apriori(partition, total_length)).flatMap(lambda result : result).distinct().collect()\n",
    "print(rdd.take(5))\n",
    "write_data_to_file(output_file_path, \"w\", candidate_items, \"Candidates:\")\n",
    "print(\"time taken for candidate items is :\", time.time() -time1)\n",
    "time2 = time.time()\n",
    "#print(candidate_items)\n",
    "\n",
    "son = rdd.mapPartitions(lambda partition : son(partition, candidate_items)).reduceByKey(lambda a,b : a+b).filter(lambda frequent_item : frequent_item[1] >= threshold).map(lambda frequent_item : frequent_item[0]).collect()\n",
    "write_data_to_file(output_file_path, \"a\", son, \"Frequent Itemsets:\")\n",
    "print(\"Duration:\" ,time.time() - start_time)\n",
    "#print(son)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3962f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(num_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c849c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
